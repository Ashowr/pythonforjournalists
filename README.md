# Python for Journalists
*Notebooks and files for the Python for Journalists course on [Learno.net](https://learno.net)*
=========================================================================================

* [What is Python anyway](#what-is-python-anyway)
* [About the course](#about-the-course)
* [1 Getting started](#getting-started)
* [Hands-on Modules](#hands-on-modules)
    * [2 Clean data](#clean-data)
    * [3 Analyse data](#analyse-data)
    * [4 Scrape data](#scrape-data)
* [Learning More, Reference And Tools](#learning-more-reference-and-tools)
* [About Us](#about-us)

What Is Python Anyway
===============================

Python is a programming language for general-purpose programming. It's popular among data journalists for its readability, ease of use and efficiency. 

About the Course
==================
The course Python for Journalists is meant for journalists looking to learn the most common uses of Python for data journalism. During four modules the course teaches you how to set up Python and all Python-related tools on your own computer. Next you'll learn how to clean up messy datasets using the Pandas library. In the thirth module you'll learn how to analyse data, again using the Pandas library. In the fourth and final module you'll learn how to automatically download data from the web, by using both the Beautiful Soup and Requests libraries to dabbling in webscraping. 

This Python for Journalists course is meant for those who dabbled in Python, but somehow didn't persevere; and for those who can't wait to dive in head first... Though no programming knowledge is required, it helps if you know what a terminal or command prompt is.


Getting Started
===============

## 1 Set Up

This module revolves around installing the right tools on your laptop. To follow along in the coming modules, you'll need Python 3, and several Python libraries like Requests, Pandas and BeautifulSoup installed. Jupyter Notebooks come highly recommended. It's recommended that you install all of this software in one go, using the [Anaconda distribution](https://anaconda.org/). This first module does not include a Jupyter Notebook.

### On your computer:

* Install the [Anaconda distribution](https://www.anaconda.com/download/#macos) to install **Python 3**, libraries Requests, Pandas, and BeautifulSoup, and Jupyter Notebooks all at once on your computer. 
  * Note: choose for the Anaconda installation that includes **Python 3**.

Hands-on Modules
==========

## 2 Clean data

In this second module we'll show you how to into your Python conda environment; how to start a Jupyter Notebook. Once that's out of the way, you'll learn how to import a CSV-file into your Jupyter Notebook, to get ready for some data cleaning. Among other things you'll learn how to search and replace values inside a column; how to change the datatype of a column; and how to extract data from a column to populate a new column. This module includes both a Jupyter Notebook (empty and completed) and a cheatsheet - all named 'clean data'.

## Analyse data

In this thirth module, you'll learn how to analyse data using the Pandas library. You'll learn how to explore your dataset, looking at summary statistics - count, median, mean, percentiles, standard deviation etc. - for each column. Next we'll look into how to sort, filter, sum and count values in columns. Finally you'll learn how to group data, creating (for those familiar with Excel) pivot tables, using the Pandas library. This module includes both a Jupyter Notebook (empty and completed) and a cheatsheet - all named 'analyse data'. 


## Scrape data

The final module revolves around scraping data using both the Requests and the BeautifulSoup libraries. Though in practice you'll likely first want to scrape data, to later clean and analyse those numbers, this module is last for training purposes. The modules on cleaning and analysing data introduced you to Python, Pandas and Jupyter Notebooks. Paving the way for some basic webscraping, including a for loop to collect data as efficient as possible. Finishing this module you should be able to write some basic webscrapers to collect data from the internet. This module includes both a Jupyter Notebook (empty and completed) and a cheatsheet - all named 'scrape data'. 

Learning More...
==================================

* XXX's [Learn Python the Hard Way]()
* XXXX [Python for Journalists]()
* Code Academy []()
* Data Camp []()
* 

About Us
========

## About LEARNO.NET 
LEARNO.NET offers convenient, accesible and premium-quality online learning for media professionals. All courses are free - as in free beer - and accessible worldwide. LEARNO.NET is an initiative of the European Journalism Centre (EJC). The EJC is a non-profit international foundation with the mission to improve and strengthen journalism and the news media in the interest of a functioning democratic public sphere. The European Journalism Centre would like to thank the Dutch Ministry of Education, Culture and Science, Google, and the World Bank, for making LEARNO.NET possible.

## About Winny de Jong
*(An official sounding bio... ;) )*  
Winny works as a data journalist for the Dutch national broadcast NOS. There she interviews data sets instead of people in order to find news before it is news. Next to that, she likes to pay it forward by blogging, talking and teaching about the importance of data literacy, how to develop ideas, and her data journalistic workflow. She has presented before for organizations like TEDx, Brussels News Summit, and several journalism colleges in both Belgium and The Netherlands. Winny grew up in Rotterdam, but now lives in Amersfoort, The Netherlands. Visit her online at [datajournalistiek.nl/en](https://datajournalistiek.nl/en) or subscribe to her [irregular data journalism newsletter](https://datajournalistiek.nl/en/newsletter/).
